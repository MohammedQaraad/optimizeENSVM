# -*- coding: utf-8 -*-
"""Second_paper_SVM_only_3/5.ipynb

Automatically generated by Colaboratory.
# -*- coding: utf-8 -*-


@author: Mohammed Qaraad 

Original file is located at
    https://colab.research.google.com/drive/1bnYiRz6HOwSHBsToEVpYE2MKvuqj3czp
"""

import pandas as pd
import numpy as np
from matplotlib import pyplot
from sklearn.preprocessing import MinMaxScaler, LabelEncoder
import csv
from sklearn.model_selection import train_test_split
from sklearn.svm import SVC
from sklearn.metrics import classification_report, confusion_matrix
import random
from google.colab import drive
drive.mount('/content/drive')
from sklearn.model_selection import StratifiedKFold
from sklearn import metrics
from sklearn.linear_model import ElasticNet
from collections import Counter
import tarfile
from sklearn.metrics import roc_curve, auc
from numpy import interp
import matplotlib.pyplot as plt

random_s = np.random.RandomState(0)

# ,'choewdary.tar.gz','golub.tar.gz','gordon.tar.gz'+
data_set_name=['chin.tar.gz','alon.tar.gz','chowdary.tar.gz','golub.tar.gz',
               'singh.tar.gz','west.tar.gz','gordon.tar.gz']
# data_set_name=['gordon.tar.gz']
plt.figure(figsize=(5,6))
plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',
         label='Luck', alpha=.8)    
import time
start = time.time()

for i in data_set_name:
  d= i.split('.')[0]
  print(d)
  file='/content/drive/My Drive/Colab Notebooks/data/'+i
  datasetname=d

  min_max_scaler = MinMaxScaler()
  with tarfile.open(file, "r:*") as tar:
    csv_path = tar.getnames()
    if(d == 'singh' or d == 'west'):
      labels = pd.read_csv(tar.extractfile(csv_path[1]), header=None)
      feature = pd.read_csv(tar.extractfile(csv_path[0]), header=None)

    else:
      labels = pd.read_csv(tar.extractfile(csv_path[0]), header=None)
      feature = pd.read_csv(tar.extractfile(csv_path[1]), header=None)
  headers = list(feature.columns)
  features = np.asarray(feature.values)
  features = min_max_scaler.fit_transform(feature)
  labels = np.transpose(np.asarray(labels.values.ravel() - 1, dtype=int))
  print(features.shape, labels.shape)

  counter = Counter(labels)
  print(counter)
  random_s = np.random.RandomState(0)

  NoRun=1
  cv = StratifiedKFold(n_splits=10,shuffle=False)
  fold_N=0
  max_fold=10

  Accuracy=np.zeros((max_fold))
  Precision=np.zeros((max_fold))
  Recall=np.zeros((max_fold))
  TP=[]
  FP=[]
  TN=[]
  FN=[]

  Specificity = np.zeros((max_fold))
  Sensitifity = np.zeros((max_fold))
  AUC = np.zeros((max_fold))
  Area_under_curve=np.zeros((max_fold))
  tprs = []
  aucs = []
  mean_fpr = np.linspace(0, 1, 100)

  
  for r in range(0,NoRun):
    fold_N=0
    i=0
    for train_index, test_index in cv.split(features,labels):
      #Data Partition 
      X_train, X_test =  features[train_index], features[test_index]
      y_train, y_test = labels[train_index], labels[test_index]
      #x_train, x_validation, y_train, y_validation = train_test_split(X_train,y_train,test_size = 0.11)

      #evaluate Fintness Function 
      svclassifier = SVC(kernel='rbf',verbose=0, random_state=random_s,probability=True) 
      svclassifier.fit(X_train, y_train)
      # ypred = svclassifier.predict(x_validation)
      # ValidationError=sum(ypred==y_validation)*100/y_validation.shape[0]
    
  
      # print('fold_N = ', fold_N , ' Best value of C= ', gBestPos[0],'  Best value of Sigma=',gBestPos[1],  'fmin= ', gBestValue) 
      # ResultsValidation[r][fold_N]=gBestValue
      # fold_best_postion[fold_N]= gBestPos

      # svclassifier = SVC(kernel='rbf', gamma = gBestPos[1], C = gBestPos[0] ,verbose=0, random_state=random_s)
      # svclassifier.fit(x_train, y_train)
      # ypred = svclassifier.predict(X_test)
      probas_ = svclassifier.predict_proba(X_test)
      ypred = np.argmax(probas_, axis=1)
      fpr, tpr, t = roc_curve(y_test, ypred)
      #print('fpr ',fpr) 
      #print('tpr',tpr)
      tprs.append(interp(mean_fpr, fpr, tpr))
      roc_auc = auc(fpr, tpr)
      aucs.append(roc_auc)
      #plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))
      i= i+1
      conf_matrix = confusion_matrix(y_test, ypred)
      # TP.append(conf_matrix[1][1])
      # TN.append(conf_matrix[0][0])
      # FP.append(conf_matrix[0][1])
      # FN.append(conf_matrix[1][0])
      # conf_sensitivity = (conf_matrix[1][1] / float(conf_matrix[1][1] + conf_matrix[1][0]))
      # TPR=conf_sensitivity
      
      sensitivity1 = conf_matrix[0,0]/(conf_matrix[0,0]+conf_matrix[0,1])
      # print('Sensitivity : ', sensitivity1 )

      Sensitifity[fold_N]=sensitivity1
      # conf_specificity = (conf_matrix[0][0] / float(conf_matrix[0][0] + conf_matrix[0][1]))
      # FPR= (1 - conf_specificity)
      specificity1 = conf_matrix[1,1]/(conf_matrix[1,0]+conf_matrix[1,1])
      Specificity[fold_N]=specificity1
      # auC= (float(1+TPR - FPR)/2)
      AUC[fold_N]=roc_auc
      Area_under_curve[fold_N]= roc_auc
    
      #calculate Error ratio 
      TestingError=sum(ypred==y_test)*100/y_test.shape[0]
      #ResultsTestingAcc[r][fold_N]=100-TestingError;
      #SV[r]= svclassifier.n_support_
      #print('fold_N testing error ', 100-TestingError)
      fold_N = fold_N +1
  
    print (d, "AUC = %.2f SenStd = %.2f " % (AUC.mean(), AUC.std()))
    print (d, "Sen = %.2f SenStd = %.2f " % (Sensitifity.mean(), Sensitifity.std()))
    print (d, "Spe = %.2f SenStd = %.2f " % (Specificity.mean(), Specificity.std()))
    print('Area_under_curve' , Area_under_curve)
    print('AUC' ,AUC)
    print('Sensitifity', Sensitifity)
    print('Specificity' ,Specificity)
    print (d, "AUC = %.5f SenStd = %.2f " % (AUC.mean(), AUC.std()))
    print (d, "Sen = %.5f SenStd = %.2f " % (Sensitifity.mean(), Sensitifity.std()))
    print (d, "Spe = %.5f SenStd = %.2f " % (Specificity.mean(), Specificity.std()))
    mean_tpr = np.mean(tprs, axis=0)
    mean_tpr[-1] = 1.0
    mean_auc = auc(mean_fpr, mean_tpr)
    std_auc = np.std(aucs)
    plt.plot(mean_fpr, mean_tpr,
             label=d +' Mean ROC (AUC = %0.2f $\pm$ %0.2f)' % (mean_auc, std_auc),
             lw=2, alpha=.8)



    # std_tpr = np.std(tprs, axis=0)
    # tprs_upper = np.minimum(mean_tpr + std_tpr, 1)
    # tprs_lower = np.maximum(mean_tpr - std_tpr, 0)
    # plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color='grey', alpha=.2,
    #                  label=r'$\pm$ 1 std. dev.')
print('******************************************')
end = time.time()
temp = end-start
print(temp)
hours = temp//3600
temp = temp - 3600*hours
minutes = temp//60
seconds = temp - 60*minutes
print('%d:%d:%d' %(hours,minutes,seconds))
plt.xlim([-0.05, 1.05])
plt.ylim([-0.05, 1.05])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('SVM with Rbf kernel default Parameters')
plt.legend(loc="lower right")
plt.show()